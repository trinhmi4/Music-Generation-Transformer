# Music Generation Transformer
## Introduction
This project use transformer architecture to produce music. Input to the model will be a sequence of 40 midi notes and the output will be prediction for the next note. 
## Data Source
The dataset that was being used was downloaded from https://colinraffel.com/projects/lmd/. The model uses Clean MIDI subset.
## Data Split
Due to restriction in RAM, we had to pick a random subset of 100 songs from Clean MIDI set to work with. The chosen songs are stored in <a href="https://drive.google.com/drive/folders/1ffu0J6SJt_soSpeH1jP68LV0c-MUVdV2?usp=sharing" target="_blank">Google Drive</a>
## Data Summary
## Data Transformation
## Model Figure
## Model Parameters
## Model Examples
## Training Curve
## Hyperparameter Tuning
## Quantitative Measures
## Quantitative and Qualitative Results
## Justification of Results
## Ethical Consideration
Since the model learned from existing data, so if someone use the model to generate music and make
money on it, this can be thought of as using some original artists’ work without rewarding or giving
credit to them. Moreover, AI generated music would also be unfair to the artists since they had to
spent a great amount of hours to create art whereas the model learnt from them and is able to create
art at a much faster rate. Therefore, this seems to invalidate real artists’ effort.
## Author
